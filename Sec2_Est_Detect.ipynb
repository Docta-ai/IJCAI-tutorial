{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Handling the label noise in datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this section, you will get familiar with:\n",
    "\n",
    "* Why the label noise transition matrix $T$ is important in handling label noise?\n",
    "\n",
    "* How do we estimate $T$ given a dataset with only noisy labels?\n",
    "\n",
    "* How do we detect label errors in a dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importance of $T$\n",
    "\n",
    "* Understanding the pattern/structure of label noise\n",
    "* Design robust loss functions\n",
    "* Helps label aggregation (weighted majority vote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Understand the pattern of label noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples from CIFAR-10N\n",
    "\n",
    "* CIFAR-10N: \n",
    "  * 10 classes. \n",
    "  * Each image is annotated by 3 independent human workers.\n",
    "* Aggregation labels: \n",
    "  * Take the majority vote from 3 annotations.\n",
    "  * Break ties evenly.\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td ><img src=\"tutorial_imgs/c10_agg.png\" width=\"700\"> \n",
    "\n",
    "    Figure: Label noise transition matrix of CIFAR-10N.\n",
    "</td>\n",
    "    <td>\n",
    "    * Humans can be very accurate on some classes (ship 97%, horse 96%)<br/>\n",
    "    * Humans can be inaccurate on other classes (cat 83%, deer 83%)<br/>\n",
    "    * Human annotations have bias:<br/>\n",
    "      &nbsp;&nbsp;&nbsp;&nbsp;- Horse-deer is a pair with high similarity, <b>but</b>..<br/>\n",
    "      &nbsp;&nbsp;&nbsp;&nbsp;- Humans tend to annotate deer as horse: deer &rarr; horse 0.04<br/>\n",
    "      &nbsp;&nbsp;&nbsp;&nbsp;- Humans tend <b>not</b> to annotate horse as deer: horse &rarr; deer 0.01 <br/>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples from CIFAR-100N\n",
    "\n",
    "* CIFAR-100N: \n",
    "  * 20 coarse classes, 100 fine classes. Each coarse class contains 5 fine classes.\n",
    "  * Each image is annotated by 1 independent human workers.\n",
    "\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td ><img src=\"tutorial_imgs/c100_coarse.png\" width=\"1100\"> \n",
    "\n",
    "    Figure: Label noise transition matrix of CIFAR-100N.\n",
    "</td>\n",
    "    <td>\n",
    "    * Humans can be very accurate on some classes<br/>\n",
    "      &nbsp;&nbsp;&nbsp;&nbsp;- people 94%<br/>\n",
    "    * Humans can be inaccurate on other classes <br/>\n",
    "      &nbsp;&nbsp;&nbsp;&nbsp;- medium-sized mammals 47%<br/>\n",
    "    * Human annotations have bias:<br/>\n",
    "      &nbsp;&nbsp;&nbsp;&nbsp;- man-made &rarr; natural 0.09<br/>\n",
    "      &nbsp;&nbsp;&nbsp;&nbsp;- natural &rarr; man-made 0.03 <br/>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Design robust loss functions\n",
    "\n",
    "Recall that:\n",
    "* Feature $X$, noisy label $\\widetilde Y$. \n",
    "* Model: $\\bm f(\\cdot)$ (Input: $X$, output: a column vector, probability of predicting each label class)\n",
    "* Loss function: $\\ell$.\n",
    "* Label noise transition matrix $\\bm T$, and its transpose $\\bm T^\\top$.\n",
    "\n",
    "#### Forward loss correction:\n",
    "$$\n",
    "\\ell^{\\rightarrow}(\\bm f(X),\\widetilde Y):= \\ell(\\bm T^\\top \\bm f(X),\\widetilde Y).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Helps label aggregation (weighted majority vote)\n",
    "\n",
    "Intuition:\n",
    "* Normal majority vote: each labeler has the same weight. \n",
    "  * E.g., $\\text{MV}(1,1,0) = 1$.\n",
    "* Weighted majority vote: each labeler makes mistakes with some probability. \n",
    "  * E.g., label class 1 is rare, the first two labelers are not reliable and the third labeler is reliable, we may have $\\text{MV}_\\text{Weighted}(1,1,0) = 0$.\n",
    "  * Condition:  $P(Y=1) = 0.2, T = \\begin{pmatrix} 0.8 & 0.2 \\\\ 0.7 & 0.3 \\end{pmatrix}  $\n",
    "  * Probability of label 1: $$   \\begin{align*} & P(Y=1| \\widetilde Y_1 = 1, \\widetilde Y_2 = 1, \\widetilde Y_3 = 0)  \\\\ = & \\frac{P(Y=1)}{P( \\widetilde Y_1 = 1, \\widetilde Y_2 = 1, \\widetilde Y_3 = 0)} \\cdot P(\\widetilde Y_1=1|Y=1) \\cdot P(\\widetilde Y_2=1|Y=1) \\cdot P(\\widetilde Y_3=0|Y=1) \\\\ = & \\frac{0.0126}{P( \\widetilde Y_1 = 1, \\widetilde Y_2 = 1, \\widetilde Y_3 = 0)}\\end{align*}  $$\n",
    "  * Probability of label 0: $$   \\begin{align*} & P(Y=0| \\widetilde Y_1 = 1, \\widetilde Y_2 = 1, \\widetilde Y_3 = 0)  \\\\ = & \\frac{P(Y=0)}{P( \\widetilde Y_1 = 1, \\widetilde Y_2 = 1, \\widetilde Y_3 = 0)} \\cdot P(\\widetilde Y_1=1|Y=0) \\cdot P(\\widetilde Y_2=1|Y=0) \\cdot P(\\widetilde Y_3=0|Y=0) \\\\ = & \\frac{0.0256}{P( \\widetilde Y_1 = 1, \\widetilde Y_2 = 1, \\widetilde Y_3 = 0)} \\end{align*} $$\n",
    "  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Estimate $T$\n",
    "\n",
    "* Naive approach\n",
    "* Estimate with anchor points\n",
    "* Estimate with consensus patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Naive approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Estimate with anchor points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Estimate with consensus patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Detect label errors\n",
    "\n",
    "* Detect with model confidence\n",
    "* Detect with sample influence\n",
    "* Detect with similar features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Motivation for estimating T\n",
    "Understanding (give a figure from CIFAR-N paper)\n",
    "Give equation for loss correction (refer to next section)\n",
    "Knowing T also helps aggregation (Sigmetricsâ€™15)\n",
    "Estimate T\n",
    "Anchor point (equation only, no code)\n",
    "HOC\n",
    "Equation + Figure\n",
    "Example\n",
    "Load a X matrix 100*10\n",
    "Load noisy Y (show ground truth T)\n",
    "Find 2-NN (print an example)\n",
    "Build tensor \n",
    "Solve equation \n",
    "Show transition matrix\n",
    "Detection \n",
    "Confident learning (equation + intuition)\n",
    "Influence function (def of influence function)\n",
    "SimFeat\n",
    "Equation + Figure\n",
    "Example: 2D example\n",
    "Show figure of the data points \n",
    "Use one wrongly labeled sample to show:\n",
    "Find K-NN neighbor\n",
    "Weighted majority vote\n",
    "Ranking + HOC \n",
    "Show suggestion\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
