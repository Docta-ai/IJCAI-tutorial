{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Handling the label noise in datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this section, you will get familiar with:\n",
    "\n",
    "* Why the label noise transition matrix $T$ is important in handling label noise?\n",
    "\n",
    "* How do we estimate $T$ given a dataset with only noisy labels?\n",
    "\n",
    "* How do we detect label errors in a dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importance of $T$\n",
    "\n",
    "* Understanding the pattern/structure of label noise\n",
    "* Design robust loss functions\n",
    "* Helps label aggregation (weighted majority vote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Understand the pattern of label noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples from CIFAR-10N\n",
    "\n",
    "* CIFAR-10N: \n",
    "  * 10 classes. \n",
    "  * Each image is annotated by 3 independent human workers.\n",
    "* Aggregation labels: \n",
    "  * Take the majority vote from 3 annotations.\n",
    "  * Break ties evenly.\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td ><img src=\"./tutorial_imgs/c10_agg.png\" width=\"700\"> \n",
    "\n",
    "    Figure: Label noise transition matrix of CIFAR-10N.\n",
    "</td>\n",
    "    <td>\n",
    "    * Humans can be very accurate on some classes (ship 97%, horse 96%)<br/>\n",
    "    * Humans can be inaccurate on other classes (cat 83%, deer 83%)<br/>\n",
    "    * Human annotations have bias:<br/>\n",
    "      &nbsp;&nbsp;&nbsp;&nbsp;- Horse-deer is a pair with high similarity, <b>but</b>..<br/>\n",
    "      &nbsp;&nbsp;&nbsp;&nbsp;- Humans tend to annotate deer as horse: deer &rarr; horse 0.04<br/>\n",
    "      &nbsp;&nbsp;&nbsp;&nbsp;- Humans tend <b>not</b> to annotate horse as deer: horse &rarr; deer 0.01 <br/>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples from CIFAR-100N\n",
    "\n",
    "* CIFAR-100N: \n",
    "  * 20 coarse classes, 100 fine classes. Each coarse class contains 5 fine classes.\n",
    "  * Each image is annotated by 1 independent human workers.\n",
    "\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td ><img src=\"tutorial_imgs/c100_coarse.png\" width=\"1100\"> \n",
    "\n",
    "    Figure: Label noise transition matrix of CIFAR-100N.\n",
    "</td>\n",
    "    <td>\n",
    "    * Humans can be very accurate on some classes<br/>\n",
    "      &nbsp;&nbsp;&nbsp;&nbsp;- people 94%<br/>\n",
    "    * Humans can be inaccurate on other classes <br/>\n",
    "      &nbsp;&nbsp;&nbsp;&nbsp;- medium-sized mammals 47%<br/>\n",
    "    * Human annotations have bias:<br/>\n",
    "      &nbsp;&nbsp;&nbsp;&nbsp;- man-made &rarr; natural 0.09<br/>\n",
    "      &nbsp;&nbsp;&nbsp;&nbsp;- natural &rarr; man-made 0.03 <br/>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Design robust loss functions\n",
    "\n",
    "Recall that:\n",
    "* Feature $X$, noisy label $\\widetilde Y$. \n",
    "* Model: $\\bm f(\\cdot)$ (Input: $X$, output: a column vector, probability of predicting each label class)\n",
    "* Loss function: $\\ell$.\n",
    "* Label noise transition matrix $\\bm T$, and its transpose $\\bm T^\\top$.\n",
    "\n",
    "#### Forward loss correction:\n",
    "$$\n",
    "\\ell^{\\rightarrow}(\\bm f(X),\\widetilde Y):= \\ell(\\bm T^\\top \\bm f(X),\\widetilde Y).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Helps label aggregation (weighted majority vote)\n",
    "\n",
    "Intuition:\n",
    "* Normal majority vote: each labeler has the same weight. \n",
    "  * E.g., $\\text{MV}(1,1,0) = 1$.\n",
    "* Weighted majority vote: each labeler makes mistakes with some probability. \n",
    "  * E.g., label class 1 is rare, the first two labelers are not reliable and the third labeler is reliable, we may have $\\text{MV}_\\text{Weighted}(1,1,0) = 0$.\n",
    "  * Condition:  $\\mathbb P(Y=1) = 0.2, T = \\begin{pmatrix} 0.8 & 0.2 \\\\ 0.7 & 0.3 \\end{pmatrix}  $\n",
    "  * Probability of label 1: $$   \\begin{align*} & \\mathbb P(Y=1| \\widetilde Y_1 = 1, \\widetilde Y_2 = 1, \\widetilde Y_3 = 0)  \\\\ = & \\frac{\\mathbb P(Y=1)}{\\mathbb P( \\widetilde Y_1 = 1, \\widetilde Y_2 = 1, \\widetilde Y_3 = 0)} \\cdot \\mathbb P(\\widetilde Y_1=1|Y=1) \\cdot \\mathbb P(\\widetilde Y_2=1|Y=1) \\cdot \\mathbb P(\\widetilde Y_3=0|Y=1) \\\\ = & \\frac{0.0126}{\\mathbb P( \\widetilde Y_1 = 1, \\widetilde Y_2 = 1, \\widetilde Y_3 = 0)}\\end{align*}  $$\n",
    "  * Probability of label 0: $$   \\begin{align*} & \\mathbb P(Y=0| \\widetilde Y_1 = 1, \\widetilde Y_2 = 1, \\widetilde Y_3 = 0)  \\\\ = & \\frac{\\mathbb P(Y=0)}{\\mathbb P( \\widetilde Y_1 = 1, \\widetilde Y_2 = 1, \\widetilde Y_3 = 0)} \\cdot \\mathbb P(\\widetilde Y_1=1|Y=0) \\cdot \\mathbb P(\\widetilde Y_2=1|Y=0) \\cdot \\mathbb P(\\widetilde Y_3=0|Y=0) \\\\ = & \\frac{0.0256}{\\mathbb P( \\widetilde Y_1 = 1, \\widetilde Y_2 = 1, \\widetilde Y_3 = 0)} \\end{align*} $$\n",
    "  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Estimate $T$\n",
    "\n",
    "* Naive approach\n",
    "* Estimate with anchor points\n",
    "* Estimate with consensus patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Naive approach\n",
    "If we know both the ground-truth labels and noise labels:\n",
    "$$ \\mathbb P(\\widetilde Y=j | Y=i) = \\frac{\\text{\\#Samples with true label i and noisy label j}}{\\text{\\#Samples with true label i}} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T = [\n",
      "[ 0.5\t0.5 ]\n",
      "[ 0.25\t0.75 ]\n",
      "      ]\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def est_T_naive(clean_labels, noisy_labels, num_classes):\n",
    "      T = np.zeros((num_classes, num_classes))\n",
    "      for i in range(num_classes):\n",
    "            for j in range(num_classes):\n",
    "                  T[i][j] = ((clean_labels == i) * (noisy_labels == j)).sum() / (clean_labels == i).sum()\n",
    "      matrix_with_brackets = '\\n'.join(['[ ' + '\\t'.join(map(str, row)) + ' ]' for row in T])\n",
    "\n",
    "      print(f'''T = [\n",
    "{matrix_with_brackets}\n",
    "      ]\n",
    "            ''')\n",
    "\n",
    "clean_labels = np.array([0, 1, 0, 0, 0, 1, 1, 1])\n",
    "noisy_labels = np.array([1, 1, 0, 0, 1, 1, 1, 0])\n",
    "est_T_naive(clean_labels, noisy_labels, num_classes=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Estimate with anchor points\n",
    "\n",
    "**Definition: (Anchor points)**\n",
    "A feature $x$ is an anchor point for the class $i$ if $\\mathbb P(Y = i|X=x)$ is equal to one or close to one.\n",
    "\n",
    "* Step 1: Find the anchor points according to model predictions\n",
    "  * Methods:\n",
    "  * Results:\n",
    "    ```python\n",
    "        labels_of_anchor_points = np.array([0, 1, 0, 0, 0, 1, 1, 1])\n",
    "        noisy_labels = np.array([1, 1, 0, 0, 1, 1, 1, 0])\n",
    "    ```\n",
    "* Step 2 Estimate $\\bm T$ with anchor points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T = [\n",
      "[ 0.5\t0.5 ]\n",
      "[ 0.25\t0.75 ]\n",
      "      ]\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "labels_of_anchor_points = np.array([0, 1, 0, 0, 0, 1, 1, 1])\n",
    "noisy_labels = np.array([1, 1, 0, 0, 1, 1, 1, 0])\n",
    "est_T_naive(clean_labels=labels_of_anchor_points, noisy_labels=noisy_labels, num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Estimate with consensus patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 What are consensus patterns?\n",
    "\n",
    "<img src=\"tutorial_imgs/consensus.png\" width=\"700\"> \n",
    "\n",
    "*Figure: Illustration of high-order consensus patterns.*\n",
    "\n",
    "* $\\widetilde Y_1$: The noisy label of a particular instance $i$.\n",
    "* $\\widetilde Y_2$: The noisy label of instance-$i$'s nearst neighbor.\n",
    "* $\\widetilde Y_3$: The noisy label of instance-$i$'s second nearst neighbor.\n",
    "  \n",
    "**Intuition: Consensus patterns encode $\\bm T$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Condition: $2$-NN label clusterability\n",
    "\n",
    "**Definition: (Clusterability)**\n",
    "A dataset $D$ satisfies $k$-NN label clusterability if $\\forall n \\in [N]$, the feature $x_n$ and its $k$-Nearest-Neighbor $x_{n_1}, \\cdots, x_{n_k}$ belong to the same true label class.\n",
    "\n",
    "<img src=\"tutorial_imgs/clusterability.png\" width=\"700\"> \n",
    "\n",
    "*Figure: Illustration of $k$-NN label clusterability.*\n",
    "\n",
    "**Properties**\n",
    "* $k_1$-NN label clusterability is *harder* than $k_2$-NN label clusterability when $k_1 > k_2$;\n",
    "* The cluster containing the same clean labels is not required to be a continuum, e.g., two clusters of class ``1'' can be far away;\n",
    "* The $k$-NN label clusterability only requires the existence of these feasible points, i.e., specifying the true class is not necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 Equations (sketch)\n",
    "\n",
    "$$\n",
    "\\mathbb P(\\widetilde Y_1, \\widetilde Y_2, \\widetilde Y_3) = \\textsf{Func}_3(\\bm T, \\bm p).\n",
    "$$\n",
    "\n",
    "* LHS: *Numerical* counts of consensus patterns\n",
    "* RHS: *Analytical* equations (probabilities)\n",
    "\n",
    "For example,\n",
    "$$\n",
    "\\begin{align*}\n",
    "    &\\mathbb P(\\widetilde Y_1 = \\tilde y_1, \\widetilde Y_2 = \\tilde y_2, \\widetilde Y_3 =\\tilde y_3 )   = \\sum_{i \\in [K]} \\mathbb P(Y=i) \\cdot T_{i, \\tilde y_1} \\cdot T_{i, \\tilde y_2} \\cdot T_{i, \\tilde y_3}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4 Code\n",
    "\n",
    "\n",
    "**LHS - Get numerical counts**\n",
    "\n",
    "```python\n",
    "cnt = [[] for _ in range(3)]\n",
    "cnt[0] = torch.zeros(KINDS)\n",
    "cnt[1] = torch.zeros(KINDS, KINDS)\n",
    "cnt[2] = torch.zeros(KINDS, KINDS, KINDS)\n",
    "\n",
    "for pattern in consensus_patterns:\n",
    "    cnt[0][pattern[0]] += 1\n",
    "    cnt[1][pattern[0]][pattern[1]] += 1\n",
    "    cnt[2][pattern[0]][pattern[1]][pattern[2]] += 1\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**RHS - Prepare analytical equations**\n",
    "\n",
    "```python\n",
    "c_analytical = [[] for _ in range(3)]\n",
    "c_analytical[0] = torch.mm(T.transpose(0, 1), P).transpose(0, 1)\n",
    "c_analytical[2] = torch.zeros((KINDS, KINDS, KINDS))\n",
    "\n",
    "temp33 = torch.tensor([])\n",
    "for i in range(KINDS):\n",
    "    Ti = torch.cat((T[:, i:], T[:, :i]), 1)\n",
    "    temp2 = torch.mm((T * Ti).transpose(0, 1), P)\n",
    "    c_analytical[1] = torch.cat(\n",
    "        [c_analytical[1], temp2], 1) if i != 0 else temp2\n",
    "\n",
    "    for j in range(KINDS):\n",
    "        Tj = torch.cat((T[:, j:], T[:, :j]), 1)\n",
    "        temp3 = torch.mm((T * Ti * Tj).transpose(0, 1), P)\n",
    "        temp33 = torch.cat([temp33, temp3], 1) if j != 0 else temp3\n",
    "    # adjust the order of the output (N*N*N), keeping consistent with c_est\n",
    "    t3 = []\n",
    "    for p3 in range(KINDS):\n",
    "        t3 = torch.cat((temp33[p3, KINDS - p3:], temp33[p3, :KINDS - p3]))\n",
    "        temp33[p3] = t3\n",
    "    if mode == -1:\n",
    "        for r in range(KINDS):\n",
    "            c_analytical[2][r][(i+r+KINDS) % KINDS] = temp33[r]\n",
    "    else:\n",
    "        c_analytical[2][mode][(i + mode + KINDS) % KINDS] = temp33[mode]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.5 Package: Docta\n",
    "```bash\n",
    "pip install docta.ai\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A Toy Example**\n",
    "* Synthesize a dataset of 1,000 instances\n",
    "* Binary classifications\n",
    "* Each instance has three noisy labels (given by three independent labeler)\n",
    "* *Task:* Estimate \n",
    "  * the label noise transition matrix $\\bm T$ \n",
    "  * the clean label distribution $\\bm p$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synthesize the dataset (Only synthesize the labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true T is:\n",
      "[[0.603 0.398]\n",
      " [0.206 0.794]]\n",
      "The true p is:\n",
      "[0.4 0.6]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "num_samples = 1000\n",
    "\n",
    "# Set the label noise transition matrix T\n",
    "T = [\n",
    "    [0.6, 0.4],\n",
    "    [0.2, 0.8],\n",
    "]\n",
    "\n",
    "# Set the clean label distribution p\n",
    "p = [0.4, 0.6]\n",
    "\n",
    "# Generate clean labels\n",
    "clean_labels = [0] * int(num_samples * p[0]) + [1] * (num_samples - int(num_samples * p[0]))\n",
    "np.random.shuffle(clean_labels)\n",
    "\n",
    "# Generate noisy labels\n",
    "noisy_labels = []\n",
    "for i in clean_labels: # each instance has three noisy labels\n",
    "    noisy_labels.append(np.random.choice([0, 1], size = 3, p=T[i]))\n",
    "\n",
    "# Get the true T\n",
    "true_T = np.zeros((2,2))\n",
    "true_p = np.zeros(2)\n",
    "for i in range(len(clean_labels)):\n",
    "    for j in range(len(noisy_labels[0])):\n",
    "        true_T[clean_labels[i]][noisy_labels[i][j]] += 1\n",
    "    true_p[clean_labels[i]] += 1\n",
    "true_T /= np.sum(true_T, 1).reshape(-1,1)\n",
    "true_p /= np.sum(true_p)\n",
    "\n",
    "# Set precisions\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "# Print the True T and p\n",
    "print(f\"The true T is:\\n{true_T}\")\n",
    "print(f\"The true p is:\\n{true_p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Approach: Use majority vote to estimate clean labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated T by majority vote is:\n",
      "[[0.763 0.237]\n",
      " [0.169 0.831]]\n",
      "The estimated p by majority vote is:\n",
      "[0.329 0.671]\n"
     ]
    }
   ],
   "source": [
    "mv_T = np.zeros((2,2))\n",
    "from collections import Counter\n",
    "mv_p = np.zeros(2)\n",
    "for i in range(len(clean_labels)):\n",
    "    mv_label = Counter(noisy_labels[i]).most_common(1)[0][0]\n",
    "    mv_p[mv_label] += 1\n",
    "    for j in range(len(noisy_labels[0])):\n",
    "        mv_T[mv_label][noisy_labels[i][j]] += 1\n",
    "\n",
    "mv_T /= np.sum(mv_T, 1).reshape(-1,1)\n",
    "mv_p /= np.sum(mv_p)\n",
    "\n",
    "# Print the True T and p\n",
    "print(f\"The estimated T by majority vote is:\\n{mv_T}\")\n",
    "print(f\"The estimated p by majority vote is:\\n{mv_p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate with consensus patterns (by Docta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating consensus patterns...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 27.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating consensus patterns... [Done]\n",
      "Use cpu to solve equations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1501/1501 [00:02<00:00, 606.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solve equations... [Done]\n",
      "The estimated T by Docta is:\n",
      "[[0.589 0.411]\n",
      " [0.19  0.81 ]]\n",
      "The estimated p by Docta is:\n",
      "[0.421 0.579]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from docta.apis import Diagnose\n",
    "from docta.core.report import Report\n",
    "from docta.utils.config import Config\n",
    "\n",
    "# Load config\n",
    "cfg = Config.fromfile('./config/toy.py')\n",
    "\n",
    "# Initialize the report\n",
    "report = Report()\n",
    "\n",
    "# Build a dataset\n",
    "class MyDataset:\n",
    "    def __init__(self, consensus_patterns):\n",
    "        self.consensus_patterns = consensus_patterns\n",
    "        self.label = np.asarray(noisy_labels)[:,0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.consensus_patterns)\n",
    "\n",
    "dataset = MyDataset(noisy_labels)\n",
    "\n",
    "# Estimate T and p\n",
    "estimator = Diagnose(cfg, dataset, report = report)\n",
    "estimator.hoc()\n",
    "\n",
    "# Print the True T and p\n",
    "print(f\"The estimated T by Docta is:\\n{report.diagnose['T']}\")\n",
    "print(f\"The estimated p by Docta is:\\n{report.diagnose['p_clean'].reshape(-1)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Detect label errors\n",
    "\n",
    "* Detect with model confidence\n",
    "* Detect with sample influence\n",
    "* Detect with similar features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Detect with model confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Detect with sample influence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Detect with similar features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Example with Docta\n",
    "\n",
    "\n",
    "#### 3.4.1 Dataset \n",
    "We will adopt the Iris dataset for illustration.\n",
    "\n",
    "**Basic information**\n",
    "The Iris data includes three iris species with 50 samples each as well as some properties about each flower. Here is a display of the main features/labels of the iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132</td>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
       "0   83            5.8           2.7            3.9           1.2   \n",
       "1  132            7.9           3.8            6.4           2.0   \n",
       "2   93            5.8           2.6            4.0           1.2   \n",
       "3   29            5.2           3.4            1.4           0.2   \n",
       "4   12            4.8           3.4            1.6           0.2   \n",
       "\n",
       "           Species  \n",
       "0  Iris-versicolor  \n",
       "1   Iris-virginica  \n",
       "2  Iris-versicolor  \n",
       "3      Iris-setosa  \n",
       "4      Iris-setosa  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "base_path = './data/'\n",
    "clean_iris = pd.read_csv(base_path + 'clean_Iris.csv')\n",
    "clean_iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column ``Id`` indicates the raw index of the sample in the [official Iris dataset](https://archive.ics.uci.edu/dataset/53/iris). As displayed in the above table, there are four key compenents (faetures) for categorizing the species of the iris flower: ``SepalLengthCm``, ``SepalWidthCm``, ``PetalLengthCm``, ``PetalWidthCm``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2 Synthesize label noise \n",
    "\n",
    "The following function gives an example pipeline for preparing a dataset for Docta treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def process_csv(file_path, e=0.2):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      file_path: a raw file path of your csv file that you want to process\n",
    "      e: the percentage of label errors to simulate\n",
    "      (in this Iris data, we use the clean label to simulate label errors)\n",
    "    Output:\n",
    "      df: a processed csv files with label errors,\n",
    "          each column denotes a kind of feature (changed to nemerical ones if not),\n",
    "          except for the last one which is the (noisy) target column.\n",
    "      clean_label: this is the clean target reserved for checking the Docta performances\n",
    "    \"\"\"\n",
    "    # Load your data\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # (1) Rename the last column to 'clean_target'\n",
    "    df.rename(columns={df.columns[-1]: 'clean_target'}, inplace=True)\n",
    "\n",
    "    # (2) If 'clean_target' column is not of integer type, convert it\n",
    "    if df['clean_target'].dtype != 'int':\n",
    "        le = LabelEncoder()\n",
    "        df['clean_target'] = le.fit_transform(df['clean_target'])\n",
    "\n",
    "    # (3) Convert other columns to numerical values if they are not already\n",
    "    for col in df.columns[:-1]:  # Exclude the last column\n",
    "        if df[col].dtype == 'object':  # If the column has text\n",
    "            df[col] = le.fit_transform(df[col])  # Convert text to integer\n",
    "\n",
    "    # (4) Add a new 'target' column\n",
    "    n_unique = df['clean_target'].nunique()\n",
    "    def generate_target(val):\n",
    "        rand_val = np.random.random()\n",
    "        if rand_val < e:\n",
    "            new_val = np.random.choice([i for i in range(n_unique) if i != val])\n",
    "        else:\n",
    "            new_val = val\n",
    "        return new_val\n",
    "\n",
    "    df['target'] = df['clean_target'].apply(generate_target)\n",
    "    accuracy = (df['target'] == df['clean_target']).mean() * 100\n",
    "    # Print the accuracy\n",
    "    print(f\"Label error rate: {100 - accuracy:.2f}%\")\n",
    "    clean_label = df['clean_target'].tolist()\n",
    "    # Remove the clean label\n",
    "    df = df.drop(columns=['Id', 'clean_target'], axis=1)\n",
    "\n",
    "    return df, clean_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synthesize and save the noise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label error rate: 25.33%\n"
     ]
    }
   ],
   "source": [
    "noisy_df, clean_label = process_csv(base_path + 'clean_Iris.csv', e=0.25)\n",
    "noisy_df.to_csv(base_path + 'noisy_Iris.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabular-data load finished\n",
      "Detecting label errors with simifeat.\n",
      "Estimating consensus patterns...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 165.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating consensus patterns... [Done]\n",
      "Use cpu to solve equations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1501/1501 [00:04<00:00, 361.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solve equations... [Done]\n",
      "Use SimiFeat-rank to detect label errors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 695.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimiFeat] We find 37 corrupted instances from 150 instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from docta.apis import Diagnose\n",
    "from docta.core.report import Report\n",
    "from docta.utils.config import Config\n",
    "from docta.datasets import TabularDataset\n",
    "\n",
    "# Load config\n",
    "cfg = Config.fromfile('./config/label_error_tabular.py')\n",
    "\n",
    "\n",
    "dataset = TabularDataset(root_path=cfg.data_root)\n",
    "cfg.num_classes = len(np.unique(dataset.label))\n",
    "test_dataset = None\n",
    "print('Tabular-data load finished')\n",
    "\n",
    "# Initialize the report\n",
    "report = Report()\n",
    "\n",
    "from docta.apis import DetectLabel\n",
    "from docta.core.report import Report\n",
    "report = Report()\n",
    "detector = DetectLabel(cfg, dataset, report = report)\n",
    "detector.detect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Motivation for estimating T\n",
    "Understanding (give a figure from CIFAR-N paper)\n",
    "Give equation for loss correction (refer to next section)\n",
    "Knowing T also helps aggregation (Sigmetrics’15)\n",
    "Estimate T\n",
    "Anchor point (equation only, no code)\n",
    "HOC\n",
    "Equation + Figure\n",
    "Example\n",
    "Load a X matrix 100*10\n",
    "Load noisy Y (show ground truth T)\n",
    "Find 2-NN (print an example)\n",
    "Build tensor \n",
    "Solve equation \n",
    "Show transition matrix\n",
    "Detection \n",
    "Confident learning (equation + intuition)\n",
    "Influence function (def of influence function)\n",
    "SimFeat\n",
    "Equation + Figure\n",
    "Example: 2D example\n",
    "Show figure of the data points \n",
    "Use one wrongly labeled sample to show:\n",
    "Find K-NN neighbor\n",
    "Weighted majority vote\n",
    "Ranking + HOC \n",
    "Show suggestion\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
